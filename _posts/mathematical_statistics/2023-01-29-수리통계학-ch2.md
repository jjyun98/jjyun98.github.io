---
# layout: post
title: "[수리통계학] ch.2"
categories: 
  - Mathematical Statistics
tags:
  - Mathematical Statistics
  - Theory
toc: true
toc_sticky: true
use_math: true
---
**다변량 분포(Multivariate Distributions)**<br>
다변량 분포(확률벡터, joint, 주변분포), 이항 확률변수, 조건부 분포, 상관계수, 다변량 분산-공분산 행렬, 자코비안, 선형결합

## 2.1) 두 확률변수의 분포

### 확률벡터, joint

표본공간이 C인 확률실험이 주어졌을 때 C의 각 원소 c에 단 하나의 수의 순서쌍 
$X_1(c) = x_1, X_2(c) = x_2$를 대응시키는 두 확률 변수 $X_1$과 $X_2$를 생각해보자. 이 때의 <br>
$(X_1, X_2)$를 `확률벡터(random vector)`라고 한다.(한 쌍을 하나의 덩어리)<br>
$(X_1, X_2)$의 `공간(space)`은 순서쌍 $D = [(x_1, x_2) : x_1 = X_1(c), x_2 = X_2(c), c \in C]$이다.

D를 확률벡터 $(X_1, X_2)$에 대한 공간이라고 하자. A가 D의 부분집합이면 하나의 확률변수인 경우와 마찬가지로 사건 A라고 한다. $P_{X_1,X_2}[A]$로 나타내는 사건 A의 확률을 정의하고자 한다. 누적분포함수(cumulative distribution function, cdf)의 개념으로$ P_{X_1,X_2}$를 유일하게 결정할 수 있으며,
두 확률변수 $X_1, X_2$의 누적분포함수(cdf)를 나타내면 모든 $(x_1, x_2) \in R^2$에 대해 
$$F_{X_1,X_2}(x_1, x_2) = P[{X_1 \le x_1} \cap {X_2 \le x_2}]$$

이라 하고 이를 `결합누적분포함수(joint cumulative distribution function)`라고 한다.

이 때 $(X_1, X_2)$의 `결합확률질량함수(joint probability mass function)`는 모든 $(x_1, x_2) \in D$에 대해 다음과 같이 정의된다.<br>
$$p_{X_1,X_2}(x_1, x_2) = P[X_1 = x_1, X_2 = x_2]$$

확률변수에서와 마찬가지로 pmf는 cdf를 유일하게 결정한다. 다음의 두 성질 또한 특징이다.<br>
1) $0 \le p_{X_1,X_2}(x_1, x_2) \le 1$<br>
2) $\sum_{D}\sum p_{X_1,X_2}(x_1, x_2) = 1$

### 주변분포

$(X_1, X_2)$를 확률벡터라고 하자. X_1과 X_2 각각은 확률변수이다. 이에 대한 분포는 다음에 제시한 것처럼 $(X_1, X_2)$의 결합분포로부터 구할 수 있다.<br>
$x_1$에서 $X_1$의 cdf를 정의하는 사건은 {$X_1 \le x_1$}임을 상기하자. 그러나

$$(X_1 \le x_1) = (X_1 \le x_1) \cap(-\infty \le X_2 \le \infty) = (X_1 \le x_1, -\infty < X_2 < \infty)$$

확률을 구하면 모든 $x_1 \le R$에 대해 다음과 같다.<br>
$$F_{X_1}(x_1) = P [ X_1 \le x_1; -\infty < X_2 < \infty]$$                                            
<br>

이 식은 $F_{X_1}(x_1) = \displaystyle{lim_{x_2 -> \infty}F(x_1, x_2)}$로 쓸 수 있다. 이와 같이 cdf들 사이에 관계를 갖게 되는데, 이것은 $(X_1, x_2)$가 연속형인지 이산형인지에 따라서 pdf 또는 pmf로 확장할 수 있다.<br>
우선 이산형인 경우에 $D_{X_1}$이 $X_1$의 받침이라고 하면 $x_1 \in D_{X_1}$에 대해 다음과 같다.<br>

$$F_{x_1}(x_1) = \displaystyle{\sum\sum_{w_1 \le x_1, -\infty < x_2 < \infty} p_{X_1, X_2}(w_1, x_2)} = \displaystyle{\sum_{w_1 \le x_1}(\sum_{x_2 < \infty}p_{X_1, X_2}(w_1, x_2))}$$
<br>
cdf의 유일성에 의해 괄호 안에 있는 값은 $w_1$에서의 $X_1$의 pmf여야 한다. 즉 모든 $x_1 \in D_{X_1}$에 대해<br>

$$p_{X_1}(x_1) = \sum_{x_2 < \infty}p_{X_1, X_2}(x_1, x_2)$$
<br>
따라서 $X_1$이 $x_1$일 확률을 구하기 위해 $x_1$을 고정하고 모든 $x_2$에 대해 $p_{X_1, X_2}$를 합한다.<br>
이 때 표를 그려보면 표의 마지막 행 또는 열에 한쪽을 고정한 합을 구하게 되는데 이러한 표의 주변에 기록되는 모습으로 인해 `주변(marginal) pmf`라 한다.

다음으로 연속형인 경우를 생각해 보면 $D_{X_1}$이 $X_1$의 받침이라면 $x_1 \in D_{X_1}$에 대해 식은 다음과 같다.<br>
$$F_{X_1}(x_1) = \int^{x_1}_{-\infty}\int^{\infty}_{-\infty}f_{X_1, X_2}(w_1, x_2)dx_{2}dw_{1} = \int^{x_1}_{-\infty}(\int^{\infty}_{-\infty}f_{X_1, X_2}(w_1, x_2)dx_{2})dw_1 $$<br>
cdf의 유일성에 의해 괄호 안에 있는 값은 $w_1$에서의 $X_1$의 pdf여야 한다. 즉 모든 $x_1 \in D_{X_1}$에 대해<br>
$$f_{X_1}(x_1) = \int^{\infty}_{-\infty}f_{X_1, X_2}(x_1, x_2)dx_2$$<br>
따라서 연속형인 경우 $X_1$의 주변 pdf는 $x_2$에 대해 적분함으로써 구할 수 있다. 마찬가지로 $X_2$의 주변 pdf는 $x_1$에 대해 적분함으로써 구한다.

### 확률벡터의 적률생성함수

$X = (X_1, X_2)^\prime$을 확률벡터라고 하자. $h_1$과 $h_2$가 양수일 때 $|t_1| < h_1$과 $|t_2| < h_2$에 대해<br>
$E(e^{t_1X_1 + t_2X_2})$가 존재하면 이것을 $M_{X_1, X_2}(t_1, t_2)$로 표기하고 X의 `적률생성함수(moment generating function, mgf)`라고 한다.

일변량의 경우와 마찬가지로, 만약 확률벡터의 mgf가 존재하면 그것은 확률벡터의 분포르르 유일하게 결정한다.<br>
$t = (t_1, t_2)^\prime$이라면 X의 mgf는 다음과 같이 나타낼 수 있다.<br>
$$ M_{X_1, X_2}(t) = E[e^{t^\prime X}] $$ 

따라서 이것은 확률변수 mgf와 매우 유사하다. 또한 $X_1$과 $X_2$의 mgf는 각각 $M_{X_1, X_2}(t_1, 0)$과 $M_{X_1, X_2}(0, t_2)$임을 바로 
알 수 있다.<br> 혼동되지 않으면 M의 하첨자를 없애기도 한다.

## 2.2) 변환 : 이항 확률변수

$(X_1, X_2)$가 확률벡터이고, $(X_1, X_2)$의 결합분포를 알고 있으며, $(X_1, X_2)$의 변환, 즉 $Y = g(X_1, X_2)$의 분포를 찾는다고 가정하자.
그러면 Y의 cdf를 구할 수 있을지도 모른다. 또 다른 방법은 일변량 확률변수에 대해 했던 것처럼 변환을 사용하는 것인데 그대로 확률벡터로 확장한다.

확률변수 함수의 분포를 구하는 방법에는 변수변환과 cdf 기법 말고도 
`적률생성함수 기법(moment generating function(mgf) technique)`이라고 부르는 또 다른 방법이 있다.<br>
이것은 확률변수의 선형함수에 잘 적용되는데 $Y = g(X_1, X_2)$일 때 E(Y)가 존재하면 연속형인 경우 다음과 같다.<br>
$E(Y) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(x_1,x_2)f_{X_1,X_2}(x_1,x_2)dx_1dx_2$<br>
이산형인 경우에는 적분을 합으로 대체하면 된다. 분명하게 함수 $g(X_1, X_2)$는 exp{tu($X_1, X_2$)}가 될 수 있으며, 따라서 함수 $Z = u(X_1, X_2)$의 mgf를 구할 수 있다.<br> 만약 이 mgf가 특정분포에 속한다는 것을 알 수 있으면 Z는 그 분포를 따를 것이다. 
                                                

## 2.3) 조건부 분포와 기댓값

일단 여기서 다루는 것은 2개 이상의 확률변수에서의 조건부 분포인데 자세히 말하면 다른 변수가 특정 값일 때 한 확률변수의 분포에 대해서 설명한다.<br>
$X_1$과 $X_2$를 받침 S에서는 양수이고 그 외에서는 0인 joint pmf $p_{X_1,X_2}(x_1, x_2)$를 가진 이산형 확률변수라고 할 때 $p_{X_1}(x_1)$과 $p_{X_2}(x_2)$가 각각 $X_1$과 $X_2$의 marginal pdf이고, $x_1$을 $X_1$의 받침에 있는 점이라고 하자. 따라서 $p_{x_1}(x_1) > 0$이다.<br>
조건부 확률의 정의에 의해 $X_2$의 받침 $S_{X_2}$에 있는 모든 $x_2$에 대해<br>
$$P(X_2 = x_2|X_1 = x_1) = \frac{P(X_1 = x_1, X_2 = x_2)}{P(X_1 = x_1)} = \frac{p_{X_1,X_2}(x_1, x_2)}{p_{X_1}(x_1)}$$<br>
이 함수를 다음과 같이 정의한다.<br>
$$p_{X_2|X_1}(x_2|x_1) = \frac{p_{X_1,X_2}(x_1, x_2)}{p_{X_1}(x_1)}, x_2 \in S_{X_2}$$<br>
이를 $X_1 = x_1$이 주어졌을 때 확률변수 $X_2$의 `조건부 pmf(conditional pmf)`라고 한다.

- 성질<br>
a) $E[E(X_2|X_1)] = E(X_2)$<br>
b) $Var[E(X_2|X_1)] \le Var(X_2)$<br>
c) $Var(X_2) = E[Var(X_2|X_1)] + Var[E(X_2|X_1)]$

## 2.4) 독립인 확률변수

X, Y가 독립이면 $f_{X, Y}(x, y) = f_X(x) * f_Y(y)$<br>
즉, `결합 pdf` = 각각의 `marginal pdf`의 곱

cdf도 위 법칙 성립한다.

추가)<br>
$X_1$과 $X_2$는 독립인 확률변수면<br>
$$P(a < X_1 \le b, c < X_2 \le d) = P(a < X_1 \le b)*P(c < X_2 \le d)$$

추가)<br>
$X_1$과 $X_2$가 독립이며 $E(u(X_1))$과 $E(v(X_2))$가 존재한다면<br>
$$E[u(X_1)v(X_2)] = E[u(X_1)]E[v(X_2)]$$

추가)<br>
$X_1$과 $X_2$가 독립이면<br>
$$M(t_1, t_2) = M(t_1, 0)M(0, t_2)$$

## 2.5) 상관계수

(X, Y)가 확률벡터를 나타낸다고 하자. 위에서 X와 Y간의 독립성에 대해 다뤘는데 만약 X와 Y가 의존한다면 어떻게 되고, 어떻게 관련되어 있을까?<br>
의존성에는 여러가지 척도가 있는데 X와 Y 사이의 `선형성(linearity)`을 측정하는 (X, Y)의 결합분포의 모수 $\rho$를 알아본다.<br>
이 절에서 다루는 모든 기대값은 존재한다고 가정한다.

(X, Y)가 결합분포를 갖는다고 하자. X와 Y의 평균을 각각 $\mu_1, \mu_2$로 표기하고, 각각의 분산을 $\sigma_1^2, \sigma_2^2$로 표기하자.<br>
(X, Y)의 `공분산(covariance)`은 Cov(X, Y)로 나타내며 다음 기댓값으로 정의된다.<br>
$$Cov(X, Y) = E[(X - \mu_1)(Y - \mu_2)]$$

기댓값의 선형성에 의해 다음과 같이도 표현 가능하다.<br>
$$Cov(X, Y) = E(XY) - E(X)E(Y)$$

$\sigma_1$과 $\sigma_2$가 각각 양수이면 X와 Y 사이의 `상관계수(correlation coefficient)`는 다음과 같이 정의된다.<br>
$$\rho = \frac{E[(X - \mu_1)(Y - mu_2)]}{\rho_1\rho_2} = \frac{Cov(X, Y)}{\sigma_1\sigma_2}$$

두 확률변수의 곱에 대한 기댓값은 각 기댓값의 곱에 두 확률변수 간 공분산을 더한 것과 같음을 유의해야 한다.<br>
$$E(XY) = \mu_1\mu_2 + Cov(X, Y) = \mu_1\mu_2 + 
\rho\sigma_1\sigma_2$$

## 2.6) 여러 확률변수로의 확장

두 확률변수에 대한 기법은 n개의 확률변수로 바로 확장될 수 있다. 다음은 확률변수 n개의 공간에 대한 정의이다.<br>
표본 공간 C에서의 확률실험을 생각해 보자. 확률변수 $X_i$는 각 요소 $c \in C$에 단 하나의 실수 $X_i(c) = x_i(i = 1, 2, ..., n)$를 부여한다고 하자.<br>
$(X_1, ..., X_n)$을 n차원 `확률벡터(random vector)`라고 한다.<br>
확률벡터의 공간은 순서 있는 n-짝(n-tuple) $D = [(x_1, ... x_n) : x_1 = X_1(c), ..., x_n = X_n(c), c \in C]$의 집합이다. 또한 A가 공간 D의 부분집합이면 $P[(X_1, ..., X_n) \in A] = P(C)$이고, 여기서 $C = [c : c \in C$이고 $(X_1(c), ..., X_n(c)) \in A]$이다.
                                                                                     

이 절에서는 벡터 개념을 사용하는데 $(X_1, ..., X_n)^\prime$을 n차원 열벡터 X로, 그리고 확률변수의 관측값 $(x_1, ..., x_n)^\prime$을 x로 표기한다.<br> 
결합 cdf는 다음과 같이 정의한다.<br>
$$F_X(X) = P[X_1 \le x_1, ..., X_n \le x_n]$$

n개의 확률변수 $X_1, ... X_n$은 이산형 또는 연속형이며, 그 형태에 따른 분포를 갖는다. 즉 결합 cdf는 다음과 같이 나타낸다.<br>
$$F_X(X) = \sum_{w_1 \le x_1, ..., w_n \le x_n} \cdot\cdot\cdot \sum p(w_1, ..., w_n)$$

또는<br>
$$F_{X}(x) = \int^{x_1}_{-\infty}\int^{x_2}_{-\infty} \cdot\cdot\cdot \int^{x_n}_{-\infty}f(w_1, ..., w_n)dw_n \cdot\cdot\cdot dw_1$$

연속형인 경우 pdf가 0인 경우를 제외하고 다음과 같다.<br>
$$ \frac{\partial^n}{\partial_{x_1} \cdot\cdot\cdot \partial_{x_n}}F_X(X) = f(X)$$

결합 pdf를 확장하는 관례에 따라 점함수 f는<br>
a) f가 정의되고 그 변수의 모든 실숫값에 대해 음이 아니며<br>
b) 그 변수의 모든 실숫값에 대한 적분이 1이면 pdf로서의 조건을 본질적으로 만족한다.<br>
마찬가지로 점함수 p는<br>
a) p가 정의되고 그 변수의 모든 실숫값에 대해 음이 아니며<br>
b) 그 변수의 모든 실숫값에 대한 합이 1이면 pmf로서의 조건을 본질적으로 만족한다.<br>
앞 절에서와 마찬가지로 때로는 확률변수의 받침 집합을 이용하는 것이 편리하다.<br>
이산형인 경우 이것은 양의 질량을 가진 D안의 모든 점일 것이며, 연속형인 경우 이것은 양의 확률을 가진 개구간에 끼워넣을 수 있는 D안의 모든 점이라고 할 수 있다.
받침 집합은 S로 표기한다.

### 독립에서의 mgf

$X_1, X_2, \cdot\cdot\cdot, X_n$을 n개의 상호 독립적인 확률변수라고 하자. 그리고 모든 i = 1, 2, ..., n에 대해
$-h_i < t < h_i, h_i > 0$일 때 $X_i$는 mgf $M_i(t)$를 갖는다고 가정하자.<br>
$k_i, k_2, \cdot\cdot\cdot, k_n$이 상수일 때 $T = \sum_{i=1}^{n}k_iX_i$라고 하면 T는 다음과 같은 mgf를 갖는다.<br>
$$M_T(t) =  \prod_{i=1}^{n}M_i(k_{i}t), -min_i(h_i) < t < min_i(h_i)$$

### 다변량 분산-공분산 행렬

두 확률변수 사이의 공분산을 n개 변수인 경우로 확장해보면, 일단 $X = (X_1, X_2, \cdot\cdot\cdot, X_n)^\prime$을 n차원 확률벡터라고 하자.<br>
$E(X) = (E(X_1), \cdot\cdot\cdot, E(X_n))^\prime$, 즉 확률벡터의 기댓값의 정의를 생각해보자.<br>
$W$를 확률변수의 m * n 행렬이라고 하고, 이를테면 확률변수 $W_{ij}$에 대해 $W = [W_{ij}]$이다. 이 행렬은 언제든지 mn * 1 확률벡터로 일렬로 배열할 수 있다.<br>
따라서 확률행렬의 기댓값을 다음과 같이 정의한다.<br>
$$E[W] = [E(W_{ij})]$$<br>
이는 기댓값 연산자의 선형성에 의해 설명될 수 있다.<br>
추가) $W_1$과 $W_2$를 확률변수의 m * n 행렬이라고 하고, 또한 $A_1$과 $A_2$를 상수의 k * m 행렬, B를 상수의 n * l 행렬이라고 하자. 그러면 다음이 성립한다.<br>
$$E[A_1W_1 + A_2W_2] = A_1E[W_1] + A_2E[W_2]$$<br>
$$E[A_1W_1B] = A_1E[W_1]B$$

$X = (X_1, \cdot\cdot\cdot, X_n)^\prime$을 $\sigma_i^2 = Var(X_i) < \infty$인 n차원 확률벡터라고 하자.<br>
X의 평균은 $\mu = E[X]$이며, 이에 대한 `분산-공분산 행렬(variance-covariance matrix)`은 다음과 같이 정의한다.<br>
$$Cov(X) = E[(X - \mu)(X - \mu)^\prime] = [\sigma_{ij}]$$<br>
여기서 $\sigma_{ii}$는 $\sigma_i^2$을 의미한다.

분산 공분산 행렬의 형태는 Symmetric(대칭)이다.

$X = (X_1, \cdot\cdot\cdot, X_n)^\prime$을 $\sigma_i^2 = Var(X_i) < \infty$인 n차원 확률벡터라고 하자. A가 상수의 m * n 행렬이면 다음 식이 성립한다.<br>
$$ Cov(X) = E[XX^\prime] - \mu\mu^\prime$$
$$ Cov(AX) = ACov(X)A^\prime$$

모든 분산-공분산 행렬은 `positive-semi-definite( = psd)`이다. 즉, 모든 벡터 $a \in R^n$에 대해 $a^\prime Cov(X)a \ge 0$이다.<br>
이를 알아보기 위해 X가 확률벡터이고 a가 상수인 n * 1벡터라고 하자. 그러면 $Y = a^\prime X$는 확률변수이고 음이 아닌 분산을 갖는다. 즉,<br>
$$0 \le Var(Y) = Var(a^\prime X) = a^\prime Cov(X) a$$
따라서 Cov(X)는 psd이다.

> 참고)<br>
$X^t A X$ 이 형태를 quadratic form(이차형식)이라 하고<br>
$X^t A X \ge 0$이면 positive-semi-definite<br>
$X^t A X > 0$이면 positive-definite이라 한다.

## 2.7) 여러 확률변수의 변환

앞에서 두 연속형 확률변수의 함수의 결합 pdf를 결정하는 것은 이중적분에서 변수변환을 실시해야 하는, 해석학에서의 정리에 대한 따름정리였음을 알 수 있다.<br>
이 정리는 n 다중적분에 대해 자연적으로 다음과 같이 확장할 수 있다. n차원 공간 S의 부분집합 A에 대해 취한 형식이 다음과 같은 적분을 고려하자.<br>
$$\int \cdots \int_A f(x_1, ..., x_n)d_{x_1}d_{x_2} \cdots d_{x_n}$$

다음의 확률변수와 역함수는 S를 $y_1, y_2, \cdots, y_n$ 공간에 있는 T로 사상하여 S의 부분집합 A를 T의 부분집합 B로 사상하는 일대일 변환을 정의한다고 하자.<br>
$$y_1 = u_1(x_1, \cdots, x_n), y_2 = u_2(x_1, \cdots, x_n), \cdots, y_n = u_n(x_1, \cdots, x_n)$$
$$x_1 = w_1(y_1, \cdots, y_n), x_2 = w_2(y_1, \cdots, y_n), \cdots, x_n = w_n(y_1, \cdots, y_n)$$

역함수의 첫 번째 편도함수(편미분 한번한 함수)는 연속이고 다음 n * n 행렬식(자코비안)이 T에서 0이 아니라고 하면

$$J =
\begin{bmatrix}
\frac{\partial x_1}{\partial y_1} & \cdots & \frac{\partial x_1}{\partial y_n} \\
\vdots & \ddots & \vdots \\
\frac{\partial x_n}{\partial y_1} & \cdots & \frac{\partial x_n}{\partial y_n}
\end{bmatrix}$$

다음을 얻는다.<br>
$$\int \cdots \int_A f(x_1, ..., x_n)d_{x_1}d_{x_2} \cdots d_{x_n}$$
$$= \int \cdots \int_B f[w_1(y_1, ..., y_n), w_2(y_1, ..., y_n), ..., w_n(y_1, ..., y_n)]|J|d_{y_1}d_{y_2} \cdots d_{y_n}$$

역함수를 다루기 때문에 일대일 대응 함수가 아닌경우 복잡해진다.

## 2.8) 확률변수의 선형결합

아래는 확률변수의 선형결합에 대한 몇 가지 결과를 요약한 내용이다. 먼저 $(X_1, ..., X_2)^\prime$이 확률벡터를 나타낸다고 하자.<br>
이러한 변수들의 선형결합을 다루고, 특정한 상수 $a_1, a_2, ..., a_n$에 대해 일반적으로 다음과 같이 나타낸다.<br>
$$T = \sum_{i=1}^{n}a_i X_i$$

여기서는 T의 평균과 분산에 대한 표현을 구한다. T의 평균은 기댓값의 선형성에 따른 즉각적인 결과이다. 결과를 공식적으로 정리하면

T의 분산을 구하기 위해 먼저 공분산에 대한 일반적인 결과 제시하면<br>
T는 선형결합이고, W는 확률변수 $Y_1, Y_2, ..., Y_m$과 특정 상수 $b_1, b_2, ..., b_m$에 대해 $W = \sum_{i=1}^{m}b_i Y_i$로 주어진 또 다른 션형결합이라고 가정하자.<br>
$T = \sum_{i=1}^{n} a_i X_i$이고, $W = \sum_{i=1}^{n}b_i Y_i$라고 하자. i =1, 2, ..., n과 j = 1, 2, ..., m에 대해 다음이 성립한다.<br>
$$ Cov(T, W) = \sum_{i=1}^{n}\sum_{j=1}^{m}a_i b_j Cov(X_i, Y_j) $$

T의 분산을 구하기 위해 위의 식에서 단순히 W를 T로 대체하면 다음의 결과가 나온다.<br>
$$Var(T) = Cov(T, T) = \sum_{i=1}^{n}a_{i}^{2}Var(X_i) + 2\sum_{i < j}a_{i}a_{j}Cov(X_i, X_j)$$

$X_1, ..., X_n$이 독립인 확률변수이면 모든 쌍별 공분산은 0이다. 이는 $Cov(X_i, X_j) = 0$을 의미한다.

$X_1, ..., X_n$이 독립인 확률변수이고 $Var(X_i) = \sigma_i^2$이면 다음 결과가 나온다.<br>
$$ Var(T) = \sum_{i=1}^{n}a_i^2\sigma_i^2$$<br>
이 결과를 얻기 위해서는 단지 모든 $X_i$와 $X_j$가 무상관(uncorrelated)이면 된다.<br>
다음으로 독립성 외에도 확률변수가 동일한 분포를 갖는다고 가정한다. 이러한 확률변수의 모음을 `확률표본`이라고 한다.

확률변수 $X_1, ..., X_n$이 독립이고 동일하게 분포되어 있어 각 $X_i$가 같은 분포를 가지면, 이러한 확률변수가 공통된 분포에서 크기가 n인 `확률표본(random sample)`을 구성하나고 말한다. 독립이고 동일하게 분포되어 있는 것을 축약하여 `iid`라고 한다.
