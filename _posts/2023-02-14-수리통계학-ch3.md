---
layout: post
title: "수리통계학 ch.3"
categories: Theory
use_math: true
---
**몇 가지 특수한 분포**<br>
베르누이 시행, 이항분포, 다항분포

## 3.1) 이항분포와 관련 분포(이산형 분포)

### 베르누이 분포

`베르누이 실험(Bernoulli experiment)`은 확률실험으로, 그 결과는 성공 또는 실패(예: 남자 또는 여자, 생존 또는 죽음, 무결함 또는 결함)와 같이 서로 배타적으로 전체를 이루는 두 가지 방법 중 하나로 분류될 수 있다. 일련의 `베르누이 실행(Bernoulli trial)`은 베르누이 실험을 독립적으로 여러번 시행했을 때 발생하고, 이 때 성공 확률 p는 시행마다 동일하게 유지된다. 즉 이러한 일련의 과정에서 p는 각 시행에서 발생하는 성공의 확률을 나타낸다.<br>

확률변수 X는 성공일 때 1, 실패일 때 0이라면 그 때 X의 pmf는 다음과 같이 표현되고 이 때 X가 `베르누이 분포(Bernoulli distribution)`을 따른다고 말한다.<br>
$$
p(x) = p^x(1-p)^{1-x}, x = 0,1
$$
<br>
이 때 X의 기댓값과 분산은 다음과 같다.<br>

$$
\mu = p
$$<br>

$$
\sigma^2 = p(1-p)
$$<br>

> 베르누이 시행의 조건은 다음과 같다.<br>
a) s or f 즉, 두 개의 결과뿐<br>
b) 각 시행은 서로 독립이고<br>
c) 이 때의 p = p(s)로 일정하다.<br>

### 이항분포

한번의 시행에서 두 가지 결과만을 낳는 분포를 베르누이 분포라 한다면<br>
그 때의 성공 확률이 동일하게 유지되는 일련의 독립적인 베르누이 시행을 n번 반복했을 때 전체 경우에 대한 확률을 부여한 것을 이항분포라고 한다.

이항분포의 pdf는 다음과 같다.<br>
$$
p(x) = n \choose x p^x(1-p)^{1-x}, x = 0, 1, ..., n
$$

이항분포는 다음과 같이 표현하고 상수 n과 p를 이항분포의 `모수(parameter)`라고 한다.<br>
$$
B(n, p)
$$

#### 기댓값과 분산

이항분포의 기댓값과 분산은 다음과 같다.<br>
$$\mu = np
$$<br>
$$\sigma^2 = np(1-p)
$$<br>

#### mgf

$$M_x(t) = [(1-p) + pe^t]^n
$$

> 동일한 성공확률을 가진 독립인 이항분포가 여러 개 있다면 이 확률변수의 합은 이항분포를 따른다.<br>
$i = 1, 2, ..., m$일 때 $X_i$가 이항분포 $b(n_i, p)$를 따르는 독립인 확률변수를 $X_1, X_2, ..., X_m$이라고 하면 $Y = b(\sum^{m}_{i=1} n_i, p)$를 따른다.

#### 음이항분포

성공 확률 p가 동일한 일련의 독립적인 베르누이 시행을 고려할 때 r번째 성공이 발생하기 전 이 시행에서 얻은 실패의 총횟수를 확률변수 Y라고 하자.<br>
즉 Y + r은 마지막 시행이 성공일 때 정확히 r번 성공하는 데 필요한 시행 횟수와 같다. 여기서 r은 고정된 양의 정수이다. 
Y의 pmf를 결정하기 위해 y를 [y : y = 0, 1, 2, ...]의 원소라고 하자.그러면 시행이 독립적이므로 
P(Y = y)는 처음 y + r -1의 시행에서 정확히 r - 1번의 성공을 얻을 확률과 (y + r)번째 시행에서 성공을 얻을 확률인 p를 곱한 것과 같다. 따라서 Y의 pmf는 다음과 같이 계산된다.

$$p_Y(y) = { {y+r-1} \choose {r-1} }p^r(1 - p)^y
$$

이러한 $P_y(y)$ 형태의 pmf를 가진 분포를 `음이항분포(negative binomial distribution)`라고 하며, 이와 같은 $P_Y(y)$를 음이항 pmf라고 한다.<br>
이는 $P_Y(y)$가 $P^r[1 - (1 - P)]^{-r}$을 전개한 일반적인 형태라 붙은 명칭이다.<br>
mgf는 다음과 같다.<br>
$$M(t) = p^r[1 - (1 - p)e^t]^{-r}
$$

#### 기하분포

만약 r = 1이면 Y의 pmf는 다음과 같다.<br>
$$ p_Y(y) = p(1 - p)^y
$$

또한 Y의 mgf는 $M(t) = p(1 - (1 - p)e^t]^{-1}$이다. 이렇게 r = 1인 특별한 경우에 Y는 `기하분포(geometric distribution)`를 갖는다고 한다.<br>
베르누이 시행의 관점에서 Y는 첫 번째 성공을 얻기까지 실패한 횟수이다.

### 다항분포

이항분포는 다음과 같이 다항분포로 일반화된다. 어떤 확률실험을 독립적으로 n번 반복한다고 하자. 실험의 각 반복에서는 k개의 범주 중 하나에 해당하는 단 1개의 실현값만 있다.
<br>$C_1, C_2, ..., C_k$를 범주라고 부르자. 육면체 주사위를 단져서 나온 윗면을 예로 들면 i = 1, 2, ..., 6에 대해 $C_i = {i}$이다. 
i = 1, 2, ..., k에 대해 $p_i$는 실현값이 $C_i$의 요소가 될 확률이고, $p_i$는 n번의 독립적인 반복에서 일정하게 유지된다고 가정하자.
i = 1, 2, ..., k - 1에 대해 확률변수 $X_i$를 $C_i$의 요소가 되는 실현값의 개수라고 정의하자. 
$X_k = n - X_1 - \cdots - X_{k-1}$이므로 $X_k$는 다른 $X_i$에 따라 정해진다. 따라서 결합분포를 위해서는 $X_1, X_2, ..., X_{k-1}$만 고려할 필요가 있다. $x_k = n - x_1 - \cdots - x_{k-1}$이고 $p_k = 1 - \sum^{k-1}_{j=1}p_j$일 때, 
음이 아닌 정수이고 $x_1 + x_2 + ... + x_{k-1} \le n$을 만족하는 모든 $x_1, x_2, ..., x_{k-1}$에 대해 $(X_1, X_2, ..., X_{k-1})$의 `결합 pmf`는 다음과 같다.

$$P(X_1 = x, X_2 = x_2, ..., X_{k-1} = x_{k-1}) = \frac{n!}{x_1! \cdots x_{k-1}! x_k!}p_{1}^{x_1} \cdots p_{k-1}^{x_{k-1} } p_{k}^{x_k}
$$

$(X_1, ..., X_{k-1})$은 모수 n과 $p_1, ..., p_{k-1}$을 가진 `다항분포(multinomial distribution)`를 따른다고 일컫는다.
$(X_1, ..., X_{k-1})$의 결합 `mgf`는 $M(t_1, ..., t_{k-1}) = E(exp(\sum_{i=1}^{k-1}t_{i}X_{i}))$이고, 다음과 같이 계산된다.<br>
$$M(t_1, ..., t_{k-1}) = \sum \cdots \sum \frac{n!}{x_1! \cdots x_{k-1}! x_k!}(p_1e^{t_{1} })^{x_1} \cdots (p_{k-1}e^{t_{k-1} })^{x_k-1}p_{k}^{x_k}
$$

### 초기하분포

앞에서 나온 초기하분포를 공식적으로 정의하면 N개의 물품의 묶음이 있고 이 중 D개가 불량이라고 가정하자. 크기가 n인 표본에서 불량인 물품의 개수를 X로 나타내자.
만약 표본추출이 `복원(with replacement)`이고 물품을 임의로 선택한다면 X는 n과 D/N가 모수인 이항분포를 따르게 된다. 이 경우 X의 평균과 분산은 
각각 $n(D/N), n(D/N)[(N - D)/N]$이다. 그러나 표본추출이 실제로 흔히 일어나는 `비복원(without replacement)`이라고 가정해보자. 이 경우${N}\choose{n}$ 표본은 
각각의 발생 확률이 동일하고 그중 정확히 x개의 불럄품이 있는 표본의 수는 ${ {N-D}\choose{n-x} }{ {D}\choose{x} }$ 라는 것으로부터 X의 pmf가 결정된다. 따라서 X의 pmf는 다음과 같다.<br>
$$p(x) = \frac{ { {N-D}\choose{n-x} } { {D}\choose{x} } } { {N}\choose{n} }
$$<br>
여기서 평소와 마찬가지로 `이항계수(binomial coefficient)`는 위 값이 아래 값보다 작으면 0이 된다. 이러한 X는 (N, D, n)을 
모수로 하는 `초기하분포(hypergeometric distribution)`를 따른다고 한다. 그리고 X의 평균과 분산은 다음과 같다.<br>
$$E(X) = n\frac{D}{N}
$$<br>
$$Var(X) = n{\frac{D}{N} } {\frac{N-D}{N} } {\frac{N-n}{N-1} }
$$

## 3.2) 푸아송 분포

`푸아송분포(Poisson distribution)`는 확률론에서 단위 시간 안에 어떤 사건이 몇 번 발생할 것인지를 표현하는 이산 확률 분포이다.

### pdf

pdf는 다음과 같다.<br>
$$
p(x) = \frac{e^{-\lambda}\lambda^x}{x!}
$$

$\sum_{x=0}^{\infty}p(x) = 1$이기에 p(x)는 이산형 확률변수의 pmf라는 조건을 만족한다. pmf의 형태가 p(x)인 확률변수는 모수가 $\lambda$인 `푸아송분포(Poisson distribution)`을 가지고 있다고 하며, 이러한 p(x)를 모수가 $\lambda$인 푸아송 pmf라고 한다. 이 때 $\lambda$는 단위시간동안 발생한 횟수, 즉 평균을 의미한다. 


### mgf

mgf는 다음과 같다.<br>
$$e^{\lambda(e^t - 1)}
$$

푸아송 분포의 평균과 분산은 다음과 같다.<br>
$$\mu = \lambda
$$<br>
$$\sigma^2 = \lambda
$$

### 성질

$(X_1, ..., X_{n})$이 독립인 확률변수이고 $X_i$가 모수가 $\lambda_i$인 푸아송 분포를 따른다고 가정하면 $Y = \sum^{n}_{i=1}X_i$는 
모수가 $\sum^{n}_{i=1}\lambda_i$인 푸아송 분포를 따른다.

## 3.3) $\Gamma, \chi^2, \beta$ 분포(연속형 분포)

### $\Gamma$ 분포

#### 정의

`감마 분포(Gamma distribution)`는 연속 확률 분포 중 하나로, 양의 실수 값을 가지는 확률 변수의 분포를 나타내는 분포이다.<br>
감마 분포는 `형상 모수(shape parameter)`와 `척도 모수(scale parameter)` 두 개의 모수를 가지며, 모수값에 따라 분포의 모양이 달라진다. 형상 모수는 분포의 모양을 결정하고, 척도 모수는 분포의 크기를 결정한다.<br>
감마 분포는 자연 현상에서 발생하는 여러 현상을 모델링하는데 널리 사용되며, 특히 대기과학, 물리학, 경제학, 공학, 생물학 등 다양한 분야에서 활용된다. 또한, 베이지안 통계학에서 사전 분포로 자주 사용되며, 이항 분포, 포아송 분포, 정규 분포 등의 분포와 연관성을 가지고 있다.<br>
감마 분포는 특히 일부 통계 분야에서는 시간, 거리, 금액 등 양을 모델링하는 데 사용된다. 또한, 감마 분포는 `중심극한정리(Central Limit Theorem)`에 의한 정규분포의 근사에 사용되기도 한다.

먼저 $\Gamma$ 분포를 정의하기 위해서는 $\Gamma$ 함수를 먼저 정의해야 한다. $\Gamma$ 함수는 다음과 같다.<br>
$$\Gamma(\alpha) := \int^{\infty}_{0}y^{\alpha-1}e^{-y}dy
$$

> $\Gamma$ 함수의 특성<br>
a) $\alpha$ > 1이면 다음이 성립한다.<br>
$$\Gamma(\alpha) = (\alpha-1)\Gamma(\alpha-1)
$$
<br>
b) $\alpha$가 양의 정수면 다음이 성립한다.<br>
$$\Gamma(\alpha) = (\alpha-1)!
$$<br>
c)<br>$$\Gamma(\frac{1}{2}) = \sqrt\pi
$$

$\Gamma$ 함수를 부분적분법으로 정리해보면 <br>
$$\Gamma(\alpha) = (\alpha-1)!
$$<br>
와 같은 형태가 되는데 이 때문에 $\Gamma$ 함수를 `factorial function`이라고도 부른다.

#### pdf

연속형 확률변수 X의 pdf가 $x > 0, \alpha > 0, \beta > 0$ 조건에서 다음과 같으면 $\Gamma$분포를 따른다고 한다.

$$f(x) = {\frac{1}{\Gamma(\alpha)\beta^{\alpha} } }x^{\alpha-1}e^{-x/\beta}
$$

그리고 이러한 경우 $X$는 $\Gamma(\alpha, \beta)$분포를 따른다고 표현한다.

#### mgf

mgf는 다음과 같다.

$$\frac{1}{(1-\beta t)^\alpha}
$$

$\Gamma$ 분포의 평균과 분산은 다음과 같다.<br>
$$\mu = \alpha\beta
$$<br>
$$\sigma^2 = \alpha\beta^2
$$

#### 성질

$(X_1, ..., X_{n})$이 독립인 확률변수라고 하자. $i = 1, 2, ..., n$에 대해 $X_i$가 $\Gamma(\alpha_i, \beta)$ 분포를 따르면 
$Y = \sum^{n}_{i=1}X_i$는 $\Gamma(\sum^{n}_{i=1}\alpha_i\beta)$인 분포를 따른다.<br>
예를들어 서로 독립인 $X_1$ ~ $\Gamma(3, 1)$이고 $X_2$ ~ $\Gamma(2, 1)$이면 $X_1 + X_2$ ~ $\Gamma(5, 1)$이다.

### $\chi^2$분포

#### 정의

`카이제곱분포(Chi-square distribution)`는 정규분포를 따르는 확률 변수의 `제곱 합(sum of squares)`에 대한 분포이다.<br>
카이제곱분포는 `자유도(degree of freedom)`라는 하나의 모수를 가지며, 자유도가 클수록 분포가 정규분포에 가까워진다. 자유도가 1인 경우에는 감마분포와 같은 분포이며, 자유도가 2인 경우에는 두 개의 독립적인 표준정규분포를 제곱한 값의 합으로 표현된다.<br>
카이제곱분포는 주로 통계적 가설 검정에서 사용되며, 예를 들어 `카이제곱 검정(Chi-squared test)`에서는 관측된 데이터와 기대값 사이의 차이를 검정한다. 또한, 분산의 추정이나 신뢰구간 등에도 사용된다.<br>
카이제곱분포는 자연과학, 공학, 경제학 등 다양한 분야에서 사용되며, 특히 통계학과 데이터 분석에서 중요한 역할을 한다.

r이 양의 정수일 때 $\alpha = r/2$이고 $\beta = 2$인 감마분포의 특별한 경우($\Gamma(\frac{r}{2}, 2)$)의 분포를 카이제곱분포라고 한다.

#### pdf

$0 < x < \infty$에서 연속형 확률변수 X의 pdf는 다음과 같다.

$$f(x) = {\frac{1}{\Gamma({\frac{r}{2} })2^{ {\frac{r}{2} } } } }x^{ {\frac{r}{2} }-1}{e^{-{\frac{x}{2} } } }
$$

#### mgf

mgf는 다음과 같다.<br>
$$M(t) = (1 - 2t)^{ -\frac{r}{2} }
$$

카이제곱 분포의 평균과 분산은 다음과 같다.<br>
$$\mu = \alpha\beta = (r/2)2 = r
$$<br>
$$\sigma^2 = \alpha\beta^2 = (r/2)2^2 = 2r
$$

모수 r은 카이제곱분포의 자유도라고 부른다. 카이제곱분포는 통계학에서 중요한 역할을 하고 자주 사용되기 때문에, 간단히 X가 $\chi^2(r)$을 따른다고 표현하면 
확률변수 X는 자유도가 r인 카이제곱분포를 갖는다는 것을 의미한다.

#### 참고)

X가 $\chi^2(r)$분포를 갖는다고 하자. 만약 k > -r/2이면 $E(X^k)$가 존재하고 다음과 같이 계산된다.<br>
$$E(X^k) = \frac{2^k\Gamma({\frac{r} }2  + k)}{\Gamma(\frac{r}{2})}
$$<br>
k가 음이 아닌 정수일 때 k > -(r/2)가 항상 성립한다. 따라서 $\chi^2$분포의 모든 적률이 존재하고 k번째 적률은 위의 식으로 구할 수 있다.

$\chi^2$분포는 $\Gamma$분포의 하위 분포족이므로 아래의 $\Gamma$분포에 대한 가법 성질이 $\chi^2$분포에도 성립한다.

#### 성질

$(X_1, ..., X_{n})$이 독립인 확률변수라고 하자. $i = 1, 2, ..., n$에 대해 $X_i$가 $\chi^2(r_i)$ 분포를 따르면 
$Y = \sum^{n}_{i=1}X_i$는 $\chi^2(\sum^{n}_{i=1}r_i)$ 분포를 따른다.

### $\beta$ 분포

#### 정의

`베타 분포(Beta distribution)`는 0과 1 사이의 값을 가지는 확률 변수의 분포를 나타내는 확률 분포이다.<br>
베타 분포는 두 개의 모수 a와 b에 의해 정의되는데 a와 b는 모두 0보다 큰 실수값을 가지며, 그 값이 클수록 분포의 모양이 바뀐다.<br>
베타 분포는 베르누이 분포, 이항 분포 등과 함께 사용되며, 주로 성공 확률을 모수로 가지는 베르누이 분포에서 성공 확률의 사전 분포로 사용된다. 또한, 베타 분포는 베이즈 통계학에서 사전 분포로 사용된다.<br>
베타 분포는 0과 1 사이에서 무한히 많은 값을 가지며, 모양은 모수 a와 b에 따라 크게 달라진다. a와 b가 모두 1인 경우에는 균등 분포를 가지며, a와 b의 값이 커질수록 모양이 좁아지고 뾰족해진다. 반대로 a와 b의 값이 작을수록 모양은 넓어지고 완만해진다.

앞서 설명했듯이 모델링 측면에서 $\Gamma$분포는 받침이 $(0, \infty)$인 치우친 분포에 대해 다양한 모양을 제공한다. `유계구간(bounded interval)`을 받침으로 
가진 연속형 분포는 어떠할까? 예를 들어 X의 받침이 (a, b)이고, 여기서 $-\infty < a < b < \infty$이며 a와 b는 알고 있다고 가정하자. 설명을 위해서 일반성을 
잃지 않고 a = 0, b = 1이라고 가정할 수 있다. 그렇지 않은 경우에도 확률변수 $Y = \frac{(X - a)}{(b - a)}$를 고려할 수 있기 때문이다. 여기서는 유계구간을 
받침으로 가진 분포에 대해 다양한 모양을 제공하는 분포족인 `베타분포(beta distribution)`를 설명한다.

#### pdf

$\alpha > 0, \beta > 0$에서 pdf는 다음과 같다.<br>
$$f(x) = {\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} }x^{\alpha-1}(1-x)^{\beta-1} \cdot I(0 < x < 1)
$$

#### mgf

mgf는 다음과 같다.

$$M_x(t) = \int^1_0e^{tx}{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} }x^{\alpha-1}(1-x)^{\beta-1}dx
$$

`analytic form`이 존재하지 않기 때문에 평균과 분산은 정의에 의해 도출한다.<br>
$\beta$ 분포의 평균과 분산은 다음과 같다.<br>
$$\mu = E(x) = \int^1_0{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} }x^{\alpha-1}(1-x)^{\beta-1}dx
$$<br>
$$\sigma^2 = E(x^2) - E^2(x) = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
$$

#### $\Gamma, \beta$ 분포와의 관계

$X_1$ ~ $\Gamma(\alpha, 1)$,  $X_2$ ~ $\Gamma(\beta, 1)$이면 ($X_1, X_2$은 독립)<br>
$ Y_2$ := $\frac{X_1}{X_1 + X_2}$ ~ $\beta(\alpha, \beta)$

## 3.4) 정규분포

`정규분포(Normal distribution)`란, 확률 분포 중 가장 널리 사용되는 분포 중 하나로, 대부분의 자연적인 현상에서 나타나는 현상을 설명하는데 많이 사용된다.<br>
정규분포는 종 모양의 대칭 그래프로 나타나며, 평균과 표준편차에 의해 결정된다. 평균은 그래프의 중심을 결정하고, 표준편차는 그래프의 폭을 결정한다.<br>
정규분포는 `중심극한정리(Central Limit Theorem)`와 밀접한 관련이 있고, 중심극한정리는 여러 독립적인 확률 변수의 합이 정규분포와 유사한 분포를 따르는 현상을 설명한다.

#### pdf

pdf는 다음과 같다.<br>
$$ f(x) = \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) 
$$

#### mgf

mgf는 다음과 같다.<br>
$$ M_X(t) = E\left[e^{tX}\right] = \exp\left(\mu t + \frac{\sigma^2 t^2}{2}\right) 
$$

#### 참고)

지금까지 분포와 관련하여 세 종류의 `모수`를 제시했는데 $N(\mu, \sigma^2)$에서 평균 $\mu$는 그 값이 변함에 따라 정규 pdf의 중심위치가 쉽게 변하기 때문에 
`위치 모수(location parameter)`라고 한다. 또한 $N(\mu, \sigma^2)$에서 표준편차 $\sigma$는 그 값이 변함에 따라 분포의 흩어진 정도가 변하기 때문에 
`척도 모수(scale parameter)`라고 한다. 즉 $\sigma$값이 작으면 정규 pdf의 그래프가 길고 좁은 모양이며, $\sigma$값이 크면 정규 pdf의 그래프가 넓게 퍼지고 
높지 않다. 그러나 $\mu$와 $\sigma$가 어떤 값이든 정규 pdf의 그래프는 `종 모양(bell shape)`과 비슷하다. 또한 감마분포의 $\beta$ 역시 척도 모수이다. 한편 감마분포의 
$\sigma$는 그 값이 변함에 따라 pdf그래프의 형상이 변하기 때문에 `형상 모수(shape parameter)`라고 한다. 이항분포와 푸아송 분포의 모수 p와 $\mu$도 각 분포에서 형상 모수이다.

#### 성질

1) $Z$ ~ $N(0, 1)$ 면 $Z^2$ ~ $\chi^2(1)$이다.<br>
2) $i = 1, 2, ..., n$에 대해 $X_i$가 $N(\mu_i, \sigma_i^2)$ 분포를 따르는 독립인 확률변수를 $(X_1, ..., X_{n})$이라고 하자. 
$a_1, a_2, \cdots, a_n$이 상수일 때 $Y = \sum^{n}_{i=1}a_iX_i$라고 하면 Y의 분포는 $N(\sum^{n}_{i=1}a_i\mu_i, \sum^{n}_{i=1}a_i^2\sigma_i^2)$이다.<br>
3) $(X_1, ..., X_{n})$이 iid 정규확률변수일 때 평균 $\bar{X} = n^{-1}\sum^n_{i=1}X_i$이면 $\bar{X}$는 $N(\mu, \sigma^2/n)$분포를 따른다.

#### contaminated normal distribution

= mixture of normals

정규분포의 혼합인 확률변수

예를들어 $Z$ ~ $N(0, 1)$, $I_\epsilon$ ~ $B(1, 1 - \epsilon)$이고 pdf를 찾으려고 한다.<br>
이 때 $W = I_\epsilon Z + (1 - I_\epsilon) \sigma_c Z$이면 여기서<br>
$Z = N(0, 1)$이고 $\sigma_c Z = N(0, \sigma_c^2)$이게 된다.<br>
결국 이 둘은 weight의 의미를 띄고 만약 $I_\epsilon = 0.9$라면(이는 임의로 지정하는 것이다)<br>
W라는 혼합된 분포는 $N(0, 1)$을 택할 확률이 90%, $N(0, \sigma_c^2)$을 택할 확률이 10%라는 것을 의미한다.

## 3.5) 다변량 정규분포(차후 보강 예정★)

### 이변량 정규분포

$$ f(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2} }e^{-\frac{(x-\mu)^2}{2\sigma^2} } 
$$



양의 정부호(positive definite)란, 임의의 벡터 $x$에 대해 $x^\top A x$가 0보다 큰 값을 가지는 행렬 $A$를 말합니다. 여기서 $x^\top$는 $x$의 전치(transpose)를 의미합니다.

다시 말해, 행렬 $A$가 양의 정부호라면, 임의의 벡터 $x$를 $A$와 곱한 결과가 항상 0보다 큰 값을 가집니다. 이는 $A$가 양의 정부호인 경우, $A$의 역행렬 $A^{-1}$이 존재하며, $A^{-1}$도 양의 정부호라는 것을 의미합니다.

양의 정부호는 선형 대수학에서 중요한 개념 중 하나로, 양의 정부호인 행렬은 다양한 분야에서 사용됩니다. 예를 들어, 행렬의 고유값(eigenvalue) 중에서 양의 값을 가지는 것이 있다면, 그 행렬은 양의 정부호입니다. 양의 정부호인 행렬은 최적화, 통계학, 제어 이론 등 다양한 분야에서 활용됩니다.





## 3.6) t분포와 F분포

### t분포

W는 $N(0, 1)$을 따르는 확률변수이고, V는 $\chi^2(r)$을 따르는 확률변수이며, W와 V는 서로 독립이라고 하자. W와 V의 결합 pdf를 h(w, v)라고 하면 이것은 W의 pdf와 
V의 pdf의 곱이다. 즉<br>
$$f(t) = \Gamma((v+1)/2) / (\sqrt(v\pi)\Gamma(v/2))(1+t^2/v)^((v+1)/2)
$$


이 때 새로운 확률변수 T는 다음과 같이 정리한다.<br>
$$T = \frac{W}{\sqrt{V/r} }
$$

### F분포

$U$ ~ $\chi^2(r_1)$, $V$ ~ $\chi^2(r_2)$이고 $U, V$는독립이고 이 때 $W := \frac{U/r_1}{V/r_2}$라고 정의하면<br> 이것을 자유도 $r_1, r_2$를 가진 
그리고 $W$ ~ $F(r_1, r_2)$라고 표기한다.

F분포는 모수 r_1과 r_2에 의해 결정된다.

#### pdf

#### mgf

### 스튜던트정리