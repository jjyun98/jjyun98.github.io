---
author: Jo YunHo
pubDatetime: 2022-09-11T10:00:00Z
modDatetime: 2025-01-17T15:00:00Z
title: R 모델링 완전정복 - 회귀분석부터 고급 기법까지 (11)
slug: "r-modeling-regression-analysis"
featured: false
draft: false
tags:
  - R
  - 머신러닝
  - 회귀분석
description: "R의 modelr 패키지를 활용한 모델링 기법. 회귀분석, 예측, 잔차 분석, 변수 상호작용부터 비선형 모델까지 실습 예제와 함께 체계적으로 학습합니다."
---

> 📌 참고 자료:  
> [modelr 공식 문서](https://modelr.tidyverse.org/) | [R for Data Science - Model](https://r4ds.had.co.nz/model-intro.html)

## Table of contents

## 개요

**모델링**은 데이터 과학의 핵심이며, 데이터에서 패턴을 발견하고 예측을 수행하는 강력한 도구입니다. 통계학적 모델링부터 머신러닝까지, 올바른 모델 선택과 해석이 분석의 성패를 좌우합니다.

이번 포스팅에서는 **회귀분석의 기초 개념**, **예측과 잔차 분석**, **변수 간 상호작용**, **비선형 모델링**까지 modelr 패키지를 활용하여 실습 예제와 함께 체계적으로 알아보겠습니다!

## 1. 환경 설정 및 라이브러리 로드

### 필수 패키지 설치 및 로드

```r
# 패키지 로드
library('tidyverse')  # 데이터 조작과 시각화
library('modelr')     # 모델링 도구

# 플롯 최적화 설정
options(
  repr.plot.width = 8,
  repr.plot.height = 5,
  repr.plot.res = 150
)

# 테마 설정
theme_set(theme_minimal(base_size = 10))
```

## 2. 회귀분석 기초

### 데이터 탐색과 시각화

```r
# sim1 데이터 시각화
ggplot(sim1, aes(x, y)) +
  geom_point()
```

![sim1 scatter plot](@/assets/images/2022-09-11_모델링_files/2022-09-11_모델링_6_0.png)

### 회귀선 찾기 - 원초적 접근

**회귀분석의 핵심은 데이터를 가장 잘 설명하는 선을 찾는 것**입니다. 이를 이해하기 위해 무작위로 250개의 선을 그어보겠습니다.

```r
# 250개의 랜덤한 기울기와 절편 생성
models <- tibble(
  a1 = runif(250, -20, 40),  # 절편 (y-intercept)
  a2 = runif(250, -5, 5)     # 기울기 (slope)
)

# 모든 선을 한 번에 시각화
ggplot(sim1, aes(x, y)) +
  geom_abline(
    aes(intercept = a1, slope = a2),
    data = models, alpha = 1/4
  ) +
  geom_point()
```

![250 random regression lines](@/assets/images/2022-09-11_모델링_files/2022-09-11_모델링_9_0.png)

### 최적 회귀선 찾기

#### 거리 기반 평가

```r
# 모델 함수 정의
model1 <- function(a, data){
  a[1] + data$x * a[2]  # y = a[1] + a[2] * x
}

# 거리 측정 함수 (RMSE)
measure_distance <- function(mod, data){
  diff <- data$y - model1(mod, data)
  sqrt(mean(diff^2))
}

# 예시: 특정 모델의 거리
measure_distance(c(7, 1.5), sim1)
# [1] 2.665212
```

#### 모든 모델 평가

```r
# 모든 모델에 대해 거리 계산
sim1_dist <- function(a1, a2){
  measure_distance(c(a1, a2), sim1)
}

models <- models %>%
  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))

# 가장 좋은 10개 모델 시각화
ggplot(sim1, aes(x, y)) +
  geom_point(size = 2, color = "grey30") +
  geom_abline(
    aes(intercept = a1, slope = a2, color = -dist),
    data = filter(models, rank(dist) <= 10)
  )
```

![best 10 models visualization](@/assets/images/2022-09-11_모델링_files/2022-09-11_모델링_19_0.png)

### 격자 탐색 (Grid Search)

```r
# 체계적인 격자 탐색
grid <- expand.grid(
  a1 = seq(-5, 20, length = 25),
  a2 = seq(1, 3, length = 25)
) %>%
  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))

# 최적 모델들 시각화
ggplot(grid, aes(a1, a2)) +
  geom_point(
    data = filter(grid, rank(dist) <= 10),
    size = 4, color = "red"
  ) +
  geom_point(aes(color = -dist))
```

![grid search visualization](@/assets/images/2022-09-11_모델링_files/2022-09-11_모델링_24_0.png)

### 수치적 최적화 (Newton-Raphson)

```r
# optim()을 사용한 최적화
best <- optim(c(0, 0), measure_distance, data = sim1)
best$par
# [1] 4.222248 2.051204

# 최적 회귀선 시각화
ggplot(sim1, aes(x, y)) +
  geom_point(size = 2, color = "grey30") +
  geom_abline(intercept = best$par[1], slope = best$par[2])
```

![optimal regression line](@/assets/images/2022-09-11_모델링_files/2022-09-11_모델링_29_0.png)

### lm()과의 비교

```r
# R의 내장 회귀분석
sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
# (Intercept)           x 
#   4.220822    2.051533
```

#### 💡 핵심 개념
- **RMSE**: 모델의 적합도를 측정하는 지표
- **최적화**: 오차를 최소화하는 매개변수 찾기
- **lm()**: R의 최소제곱법 기반 회귀분석

## 3. 예측과 모델 해석

### 예측값 생성

```r
# 고유한 x값에 대한 예측
grid <- sim1 %>%
  data_grid(x) %>%
  add_predictions(sim1_mod)

grid
#    x     pred
# 1  1 6.272355
# 2  2 8.323888
# 3  3 10.375421
# ...
```

### 예측선 시각화

```r
# 원데이터와 예측선 함께 표시
ggplot(sim1, aes(x)) +
  geom_point(aes(y = y)) +
  geom_line(
    aes(y = pred),
    data = grid,
    color = "red",
    size = 1
  )
```

## 4. 잔차 분석

### 잔차 계산과 해석

```r
# 잔차 추가
sim1 <- sim1 %>%
  add_residuals(sim1_mod)

# 잔차 분포 확인
ggplot(sim1, aes(resid)) +
  geom_freqpoly(binwidth = 0.5)
```

### 잔차 패턴 분석

```r
# 잔차 vs 예측값 플롯
ggplot(sim1, aes(x, resid)) +
  geom_ref_line(h = 0) +
  geom_point()
```

#### ✅ 잔차 분석 체크포인트
- **무작위 분포**: 좋은 모델의 잔차는 패턴이 없어야 함
- **등분산성**: 잔차의 분산이 일정해야 함
- **정규성**: 잔차가 정규분포를 따라야 함

## 5. 범주형 변수 모델링

### 범주형 예측변수

```r
# sim2 데이터 시각화
ggplot(sim2) +
  geom_point(aes(x, y))

# 범주형 회귀모델
mod2 <- lm(y ~ x, data = sim2)

# 예측값 생성
grid <- sim2 %>%
  data_grid(x) %>%
  add_predictions(mod2)

# 범주별 평균값이 예측값
ggplot(sim2, aes(x)) +
  geom_point(aes(y = y)) +
  geom_point(
    data = grid,
    aes(y = pred),
    color = "red",
    size = 4
  )
```

### model_matrix() - 내부 구조 이해

```r
# 더미 변수 확인
df <- tribble(
  ~ sex, ~ response,
  "male", 1,
  "female", 2,
  "male", 1
)

model_matrix(df, response ~ sex)
#   (Intercept) sexmale
# 1           1       1
# 2           1       0  
# 3           1       1
```

## 6. 변수 간 상호작용

### 연속형 + 범주형 상호작용

```r
# sim3 데이터: 연속형 x1과 범주형 x2
ggplot(sim3, aes(x1, y)) +
  geom_point(aes(color = x2))

# 두 가지 모델 비교
mod1 <- lm(y ~ x1 + x2, data = sim3)      # 독립 효과
mod2 <- lm(y ~ x1 * x2, data = sim3)      # 상호작용 효과
```

### 모델 비교 시각화

```r
# 예측값 생성
grid <- sim3 %>%
  data_grid(x1, x2) %>%
  gather_predictions(mod1, mod2)

# 모델별 예측선 비교
ggplot(sim3, aes(x1, y, color = x2)) +
  geom_point() +
  geom_line(data = grid, aes(y = pred)) +
  facet_wrap(~ model)
```

### 잔차로 모델 성능 비교

```r
# 잔차 분석
sim3 <- sim3 %>%
  gather_residuals(mod1, mod2)

ggplot(sim3, aes(x1, resid, color = x2)) +
  geom_point() +
  facet_grid(model ~ x2)
```

#### 📊 상호작용 해석
- **mod1 (+)**: 평행선 (같은 기울기, 다른 절편)
- **mod2 (*)**: 교차선 (다른 기울기, 다른 절편)

### 연속형 + 연속형 상호작용

```r
# sim4: 두 연속형 변수
mod1 <- lm(y ~ x1 + x2, data = sim4)
mod2 <- lm(y ~ x1 * x2, data = sim4)

# 격자 예측값 생성
grid <- sim4 %>%
  data_grid(
    x1 = seq_range(x1, 5),
    x2 = seq_range(x2, 5)
  ) %>%
  gather_predictions(mod1, mod2)

# 히트맵으로 시각화
ggplot(grid, aes(x1, x2)) +
  geom_tile(aes(fill = pred)) +
  facet_wrap(~ model)
```

## 7. seq_range() - 유연한 시퀀스 생성

### 기본 사용법

```r
# 기본: 최소-최대 균등분할
seq_range(c(1, 2), 5)
# [1] 1.00 1.25 1.50 1.75 2.00

# pretty: 보기 좋은 숫자
seq_range(c(0.0123, 0.923423), n = 5, pretty = TRUE)
# [1] 0.0 0.2 0.4 0.6 0.8 1.0
```

### 고급 옵션

```r
# 극값 제거 (이상치 대응)
x1 <- rcauchy(100)  # 꼬리가 긴 분포
seq_range(x1, n = 5, trim = 0.10)  # 양쪽 10% 제거

# 범위 확장
x2 <- c(0, 1)
seq_range(x2, n = 5, expand = 0.10)  # 10% 확장
# [1] -0.05  0.225  0.50  0.775  1.05
```

## 8. 비선형 모델링

### 다항식 회귀

```r
# 수식 변환 확인
df <- tribble(~y, ~x, 1,1, 2,2, 3,3)

# 잘못된 방법 (^는 상호작용 의미)
model_matrix(df, y ~ x^2 + x)
#   (Intercept) x
# 1           1 1
# 2           1 2  
# 3           1 3

# 올바른 방법 (I() 사용)
model_matrix(df, y ~ I(x^2) + x)
#   (Intercept) I(x^2) x
# 1           1      1 1
# 2           1      4 2
# 3           1      9 3
```

### poly() - 직교 다항식

```r
# 직교 다항식 사용
model_matrix(df, y ~ poly(x, 2))
#   (Intercept) poly(x,2)1 poly(x,2)2
# 1           1 -0.7071068  0.4082483
# 2           1  0.0000000 -0.8164966
# 3           1  0.7071068  0.4082483
```

### 스플라인 회귀

```r
library('splines')

# 자연 스플라인 (경계에서 선형)
model_matrix(df, y ~ ns(x, 2))
#   (Intercept) ns(x,2)1 ns(x,2)2
# 1           1 0.000000  0.000000
# 2           1 0.566263 -0.210842
# 3           1 0.344097  0.770602
```

### 비선형 함수 근사 예제

```r
# 사인 함수 + 노이즈 데이터
sim5 <- tibble(
  x = seq(0, 3.5 * pi, length = 50),
  y = 4 * sin(x) + rnorm(length(x))
)

# 다양한 차수의 스플라인 모델
mod1 <- lm(y ~ ns(x, 1), data = sim5)
mod2 <- lm(y ~ ns(x, 2), data = sim5)
mod3 <- lm(y ~ ns(x, 3), data = sim5)
mod4 <- lm(y ~ ns(x, 4), data = sim5)
mod5 <- lm(y ~ ns(x, 5), data = sim5)

# 예측 비교
grid <- sim5 %>%
  data_grid(x = seq_range(x, n = 50, expand = 0.1)) %>%
  gather_predictions(mod1, mod2, mod3, mod4, mod5, .pred = "y")

ggplot(sim5, aes(x, y)) +
  geom_point() +
  geom_line(data = grid, color = "red") +
  facet_wrap(~ model)
```

#### ⚠️ 비선형 모델링 주의사항
- **과적합**: 너무 복잡한 모델은 일반화 성능 저하
- **해석성**: 복잡할수록 해석 어려움
- **외삽**: 훈련 범위 밖 예측 위험

## 9. 결측값 처리

### 자동 제거

```r
# 결측값 포함 데이터
df <- tribble(
  ~x, ~y,
  1, 2.2,
  2, NA,
  3, 3.5,
  4, 8.3,
  NA, 10
)

# lm()은 자동으로 결측값 제거
mod <- lm(y ~ x, data = df)
# 경고: 2 observations deleted due to missingness
```

### 명시적 처리

```r
# 결측값 제거 후 모델링
df_clean <- df %>%
  filter(!is.na(x), !is.na(y))

mod_clean <- lm(y ~ x, data = df_clean)
```

## 10. 모델 성능 평가

### 교차 검증

```r
# k-fold 교차검증 (modelr 활용)
cv <- sim5 %>%
  crossv_kfold(k = 5)

# 모델별 성능 비교
models <- list(
  mod1 = ~ lm(y ~ ns(x, 1), data = .),
  mod2 = ~ lm(y ~ ns(x, 2), data = .),
  mod3 = ~ lm(y ~ ns(x, 3), data = .),
  mod4 = ~ lm(y ~ ns(x, 4), data = .),
  mod5 = ~ lm(y ~ ns(x, 5), data = .)
)

cv_results <- cv %>%
  crossing(model = names(models)) %>%
  mutate(
    mod = map2(model, train, ~ models[[.x]](.y)),
    rmse = map2_dbl(mod, test, rmse)
  )

# 성능 비교
cv_results %>%
  group_by(model) %>%
  summarise(mean_rmse = mean(rmse)) %>%
  arrange(mean_rmse)
```

## 💡 실무 활용 팁

### ✅ 모델링 워크플로우

1. **탐색적 분석**: 데이터 분포와 관계 파악
2. **기본 모델**: 단순한 선형 모델부터 시작
3. **복잡성 증가**: 상호작용, 비선형 항 추가
4. **모델 비교**: 교차검증으로 성능 평가
5. **최종 선택**: 성능과 해석성의 균형

### 📊 모델 선택 기준

| 기준 | 설명 | 중요도 |
|------|------|--------|
| **예측 성능** | RMSE, R², AIC/BIC | ⭐⭐⭐⭐⭐ |
| **해석 가능성** | 계수의 의미와 통계적 유의성 | ⭐⭐⭐⭐ |
| **일반화 능력** | 새로운 데이터에 대한 성능 | ⭐⭐⭐⭐⭐ |
| **계산 효율성** | 훈련 시간과 메모리 사용량 | ⭐⭐⭐ |

### 🎯 진단 체크리스트

```r
# 모델 진단 함수
diagnose_model <- function(model, data) {
  # 잔차 정규성 검정
  shapiro_test <- shapiro.test(residuals(model))
  
  # R-squared
  r_squared <- summary(model)$r.squared
  
  # RMSE
  model_rmse <- rmse(model, data)
  
  list(
    normality_p = shapiro_test$p.value,
    r_squared = r_squared,
    rmse = model_rmse
  )
}

# 사용 예
diagnose_model(sim1_mod, sim1)
```

## 마무리

**모델링**은 데이터에서 인사이트를 추출하는 강력한 도구이지만, 올바른 이해와 적용이 필요합니다. 이번 포스팅에서 다룬 주요 내용을 정리하면:

- **회귀분석 기초**: 최적화 원리와 최소제곱법
- **예측과 잔차**: 모델 성능 평가와 진단
- **상호작용**: 변수 간 복합 효과 모델링
- **비선형 모델**: 다항식과 스플라인을 통한 곡선 적합
- **실무 워크플로우**: 체계적인 모델 개발과 검증

**실무에서는 단순한 모델부터 시작해서 점진적으로 복잡성을 늘려가는 것이 중요**합니다. 복잡한 모델이 항상 좋은 것은 아니며, 해석 가능성과 일반화 성능 사이의 균형을 맞춰야 합니다.

특히 **교차검증**을 통한 객관적 성능 평가와 **잔차 분석**을 통한 모델 가정 검증을 습관화하면, 신뢰할 수 있는 분석 결과를 얻을 수 있습니다!

다음 포스팅에서는 **고급 모델링 기법**과 **머신러닝 알고리즘**에 대해 다뤄보겠습니다. 📊