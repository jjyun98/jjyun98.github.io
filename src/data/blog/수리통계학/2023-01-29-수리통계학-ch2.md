---
author: Jo YunHo
pubDatetime: 2025-01-16T10:00:00Z
modDatetime: 2025-01-16T10:00:00Z
title: 수리통계학 Ch.2 - 다변량 분포 (Multivariate Distributions)
slug: "mathematical-statistics-ch2-multivariate"
featured: false
draft: false
tags:
  - Mathematical Statistics
  - Multivariate Statistics
  - Joint Distribution
  - Correlation
description: "다변량 분포의 핵심 개념들을 다룹니다. 확률벡터, 결합분포, 주변분포, 조건부분포, 상관계수, 분산-공분산 행렬, 자코비안, 선형결합까지 체계적으로 정리합니다."
---

## Table of contents

수리통계학의 두 번째 장에서는 **다변량 분포(Multivariate Distributions)**를 다룹니다. 실제 데이터 분석에서는 하나의 변수보다는 여러 변수들 간의 관계를 분석하는 경우가 많기 때문에, 다변량 분포의 이해는 매우 중요합니다.

확률벡터와 결합분포부터 시작하여 주변분포, 조건부분포, 상관계수, 다변량 분산-공분산 행렬, 자코비안을 이용한 변환, 그리고 확률변수의 선형결합까지 포괄적으로 살펴보겠습니다.

## 1. 두 확률변수의 분포

### 확률벡터와 결합분포

표본공간이 C인 확률실험에서 각 원소 c에 대해 두 개의 수치를 대응시키는 함수들을 생각해봅시다.

**확률벡터 (Random Vector)**
- $(X_1, X_2)$: 두 확률변수의 순서쌍을 하나의 덩어리로 취급
- **공간(Space)**: $D = \{(x_1, x_2) : x_1 = X_1(c), x_2 = X_2(c), c \in C\}$

**결합누적분포함수 (Joint CDF)**

모든 $(x_1, x_2) \in \mathbb{R}^2$에 대해:

$$F_{X_1,X_2}(x_1, x_2) = P[X_1 \leq x_1 \cap X_2 \leq x_2]$$

**결합확률질량함수 (Joint PMF)**

이산형의 경우, 모든 $(x_1, x_2) \in D$에 대해:

$$p_{X_1,X_2}(x_1, x_2) = P[X_1 = x_1, X_2 = x_2]$$

#### ✅ PMF의 성질
1. $0 \leq p_{X_1,X_2}(x_1, x_2) \leq 1$
2. $\sum_D \sum p_{X_1,X_2}(x_1, x_2) = 1$

### 주변분포 (Marginal Distribution)

결합분포로부터 각 확률변수의 개별 분포를 구하는 방법입니다.

#### 이산형의 경우

$X_1$의 주변 PMF:
$$p_{X_1}(x_1) = \sum_{x_2 < \infty} p_{X_1,X_2}(x_1, x_2)$$

#### 연속형의 경우

$X_1$의 주변 PDF:
$$f_{X_1}(x_1) = \int_{-\infty}^{\infty} f_{X_1,X_2}(x_1, x_2) dx_2$$

### 📌 주변분포의 직관적 이해

표를 그려보면 한 변수를 고정하고 다른 변수에 대해 합(또는 적분)을 구하게 되는데, 이것이 표의 **주변(margin)**에 기록되는 모습 때문에 '주변분포'라고 부릅니다.

### 확률벡터의 적률생성함수

$\mathbf{X} = (X_1, X_2)^T$를 확률벡터라고 할 때, $h_1, h_2 > 0$에 대해 $|t_1| < h_1$, $|t_2| < h_2$에서:

$$M_{X_1,X_2}(t_1, t_2) = E[e^{t_1X_1 + t_2X_2}]$$

벡터 표기법으로는:
$$M_{\mathbf{X}}(\mathbf{t}) = E[e^{\mathbf{t}^T \mathbf{X}}]$$

## 2. 변환: 이항 확률변수

확률벡터 $(X_1, X_2)$의 결합분포를 알고 있을 때, 변환 $Y = g(X_1, X_2)$의 분포를 구하는 방법들:

### 주요 방법들
1. **CDF 기법**: Y의 CDF를 구한 후 미분
2. **변수변환**: 자코비안 이용
3. **적률생성함수 기법**: 특히 선형함수에 유용

#### ✅ MGF 기법 예시

연속형의 경우:
$$E(Y) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x_1, x_2) f_{X_1,X_2}(x_1, x_2) dx_1 dx_2$$

함수 $Z = u(X_1, X_2)$의 MGF를 구할 수 있다면, 특정 분포임을 확인할 수 있습니다.

## 3. 조건부 분포와 기댓값

### 조건부 PMF

$X_1 = x_1$이 주어졌을 때 $X_2$의 조건부 PMF:

$$p_{X_2|X_1}(x_2|x_1) = \frac{p_{X_1,X_2}(x_1, x_2)}{p_{X_1}(x_1)}$$

단, $p_{X_1}(x_1) > 0$

### 📌 조건부 기댓값의 중요 성질

a) **전체 기댓값 법칙**: $E[E(X_2|X_1)] = E(X_2)$

b) **분산 부등식**: $\text{Var}[E(X_2|X_1)] \leq \text{Var}(X_2)$

c) **전체 분산 법칙**: $\text{Var}(X_2) = E[\text{Var}(X_2|X_1)] + \text{Var}[E(X_2|X_1)]$

## 4. 독립인 확률변수

### 독립성의 정의

X와 Y가 독립이면:
$$f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y)$$

즉, **결합 PDF = 각 주변 PDF의 곱**

### 독립성의 중요한 성질들

#### ✅ 확률의 곱셈

$$P(a < X_1 \leq b, c < X_2 \leq d) = P(a < X_1 \leq b) \cdot P(c < X_2 \leq d)$$

#### ✅ 기댓값의 곱셈

$E[u(X_1)]$과 $E[v(X_2)]$가 존재하면:
$$E[u(X_1)v(X_2)] = E[u(X_1)] \cdot E[v(X_2)]$$

#### ✅ MGF의 곱셈

$$M(t_1, t_2) = M(t_1, 0) \cdot M(0, t_2)$$

## 5. 상관계수

### 공분산 (Covariance)

$(X, Y)$의 공분산:
$$\text{Cov}(X, Y) = E[(X - \mu_1)(Y - \mu_2)]$$

기댓값의 선형성에 의해:
$$\text{Cov}(X, Y) = E(XY) - E(X)E(Y)$$

### 상관계수 (Correlation Coefficient)

$\sigma_1, \sigma_2 > 0$일 때:
$$\rho = \frac{\text{Cov}(X, Y)}{\sigma_1 \sigma_2}$$

### 📌 두 확률변수 곱의 기댓값

$$E(XY) = \mu_1 \mu_2 + \text{Cov}(X, Y) = \mu_1 \mu_2 + \rho \sigma_1 \sigma_2$$

## 6. 여러 확률변수로의 확장

### n차원 확률벡터

$\mathbf{X} = (X_1, \ldots, X_n)^T$를 n차원 확률벡터라고 할 때:

**결합 CDF**:
$$F_{\mathbf{X}}(\mathbf{x}) = P[X_1 \leq x_1, \ldots, X_n \leq x_n]$$

**연속형의 경우**:
$$F_{\mathbf{X}}(\mathbf{x}) = \int_{-\infty}^{x_1} \cdots \int_{-\infty}^{x_n} f(w_1, \ldots, w_n) dw_n \cdots dw_1$$

### 독립에서의 MGF

$X_1, \ldots, X_n$이 상호독립이고 각각 MGF $M_i(t)$를 가질 때:

$$T = \sum_{i=1}^n k_i X_i$$

의 MGF는:
$$M_T(t) = \prod_{i=1}^n M_i(k_i t)$$

### 다변량 분산-공분산 행렬

$\mathbf{X} = (X_1, \ldots, X_n)^T$의 분산-공분산 행렬:

$$\text{Cov}(\mathbf{X}) = E[(\mathbf{X} - \boldsymbol{\mu})(\mathbf{X} - \boldsymbol{\mu})^T] = [\sigma_{ij}]$$

#### ✅ 분산-공분산 행렬의 성질

1. **대칭성**: $\text{Cov}(\mathbf{X})$는 대칭행렬
2. **계산 공식**: $\text{Cov}(\mathbf{X}) = E[\mathbf{X}\mathbf{X}^T] - \boldsymbol{\mu}\boldsymbol{\mu}^T$
3. **선형변환**: $\text{Cov}(A\mathbf{X}) = A \text{Cov}(\mathbf{X}) A^T$
4. **양정부호**: 모든 분산-공분산 행렬은 positive semi-definite

### 📌 Positive Semi-Definite의 의미

모든 벡터 $\mathbf{a} \in \mathbb{R}^n$에 대해:
$$\mathbf{a}^T \text{Cov}(\mathbf{X}) \mathbf{a} \geq 0$$

이는 $Y = \mathbf{a}^T \mathbf{X}$의 분산이 항상 0 이상이기 때문입니다.

## 7. 여러 확률변수의 변환

### 자코비안을 이용한 변환

n차원에서의 변환:
$$y_1 = u_1(x_1, \ldots, x_n), \ldots, y_n = u_n(x_1, \ldots, x_n)$$

**자코비안 행렬**:
$J = \begin{bmatrix}
\frac{\partial x_1}{\partial y_1} & \cdots & \frac{\partial x_1}{\partial y_n} \\
\vdots & \ddots & \vdots \\
\frac{\partial x_n}{\partial y_1} & \cdots & \frac{\partial x_n}{\partial y_n}
\end{bmatrix}$

**변환 공식**:
$\int \cdots \int_A f(x_1, \ldots, x_n) dx_1 \cdots dx_n = \int \cdots \int_B f[w_1(\mathbf{y}), \ldots, w_n(\mathbf{y})] |J| dy_1 \cdots dy_n$

## 8. 확률변수의 선형결합

### 선형결합의 평균과 분산

$T = \sum_{i=1}^n a_i X_i$일 때:

**평균**:
$E(T) = \sum_{i=1}^n a_i E(X_i)$

**분산**:
$\text{Var}(T) = \sum_{i=1}^n a_i^2 \text{Var}(X_i) + 2\sum_{i<j} a_i a_j \text{Cov}(X_i, X_j)$

### ✅ 독립인 경우

$X_1, \ldots, X_n$이 독립이면 모든 공분산이 0이므로:
$\text{Var}(T) = \sum_{i=1}^n a_i^2 \sigma_i^2$

### 확률표본 (Random Sample)

확률변수 $X_1, \ldots, X_n$이 **독립이고 동일하게 분포**(iid: independent and identically distributed)되어 있으면, 이들을 공통된 분포에서 추출한 크기 n의 **확률표본**이라고 합니다.

#### 📌 IID의 중요성

- **독립성**: 각 관측값이 서로 영향을 주지 않음
- **동일분포**: 모든 관측값이 같은 모집단에서 추출됨
- 통계적 추론의 기본 가정

## 마무리

다변량 분포는 실제 데이터 분석에서 핵심적인 역할을 합니다. **확률벡터**와 **결합분포**의 개념을 통해 여러 변수들 간의 관계를 수학적으로 모델링할 수 있으며, **상관계수**와 **분산-공분산 행렬**을 통해 변수들 간의 선형 관계를 정량화할 수 있습니다.

특히 **자코비안을 이용한 변환**은 복잡한 확률변수의 분포를 구할 때 강력한 도구이며, **확률변수의 선형결합**은 표본평균과 같은 통계량의 분포를 구하는 데 필수적입니다.

**IID 확률표본**의 개념은 통계적 추론의 기초가 되므로, 이 장에서 배운 내용들은 앞으로 배울 표본분포와 추정, 검정 이론의 토대가 됩니다.

다음 장에서는 구체적인 이산분포와 연속분포들을 살펴보면서 이론을 실제 문제에 적용하는 방법을 알아보겠습니다.